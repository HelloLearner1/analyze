# Data Processing and CI/CD Pipeline

This repository demonstrates a robust data processing pipeline using Python, Pandas, and GitHub Actions. It includes:
- A Python script (`execute.py`) to process data from a CSV file.
- Conversion of an Excel file (`data.xlsx`) to CSV format.
- A GitHub Actions workflow for automated code quality checks, data processing, and result publication.

## Project Structure

```
.
├── .github/
│   └── workflows/
│       └── ci.yml             # GitHub Actions workflow for CI/CD
├── data.xlsx                  # Source data in Excel format (committed)
├── execute.py                 # Python script for data processing (fixed and committed)
├── index.html                 # Single-file responsive HTML app (committed)
├── LICENSE                    # MIT License (committed)
├── README.md                  # This README file
└── data.csv                   # Generated from data.xlsx in CI (NOT committed)
└── result.json                # Generated by execute.py in CI (NOT committed)
```

## `execute.py` - Data Processing Script

The `execute.py` script is designed to read a CSV file named `data.csv`, process its content, and output the result as a JSON object to standard output.

**Problem and Fix:**
The original `execute.py` might have contained a non-trivial error, such as referencing an incorrect column name or failing to handle non-numeric data gracefully. The fixed version addresses these issues by:
1.  **Validating Column Existence:** Checks for the presence of 'Category' and 'Value' columns.
2.  **Robust Data Conversion:** Converts the 'Value' column to a numeric type, coercing invalid entries to `NaN` and then removing rows with missing values to prevent processing errors.
3.  **Comprehensive Error Handling:** Includes `try-except` blocks to catch `FileNotFoundError` for `data.csv` and general exceptions during processing, providing informative error messages.

This ensures the script runs reliably on Python 3.11+ with Pandas 2.3.

**Fixed `execute.py` Code:**

```python
import pandas as pd
import json
import sys

def main():
    try:
        df = pd.read_csv('data.csv')

        # Ensure correct column names
        required_columns = ['Category', 'Value']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"Missing required columns in data.csv: {', '.join(missing_columns)}")

        # Convert 'Value' to numeric, coercing errors to NaN and then dropping them
        # This handles cases where 'Value' might contain non-numeric strings
        df['Value'] = pd.to_numeric(df['Value'], errors='coerce')
        df.dropna(subset=['Value'], inplace=True)

        if df.empty:
            print(json.dumps({"error": "No valid data left after cleaning."}, indent=2))
            sys.exit(0) # Exit successfully if no data, but indicate no results

        # Perform aggregation
        # Using reset_index() to convert the grouped Series back to a DataFrame
        grouped_data = df.groupby('Category')['Value'].sum().reset_index()

        # Convert to a list of dictionaries for cleaner JSON output
        result_list = grouped_data.to_dict(orient='records')

        print(json.dumps(result_list, indent=2))

    except FileNotFoundError:
        print(json.dumps({"error": "data.csv not found. Ensure it exists in the same directory."}, indent=2))
        sys.exit(1)
    except Exception as e:
        print(json.dumps({"error": f"An unexpected error occurred: {str(e)}"}, indent=2))
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## `data.xlsx` to `data.csv` Conversion

The `data.xlsx` file is the primary data source. In the CI/CD pipeline, this Excel file is automatically converted into `data.csv` using Pandas before `execute.py` is run. This ensures that the processing script always operates on a consistent CSV format. A typical `data.xlsx` would contain columns like 'Category' and 'Value'.

*Example `data.csv` structure after conversion:*
```csv
Category,Value
A,10
B,20
A,15
C,5
B,25
A,30
```

## GitHub Actions Workflow (`.github/workflows/ci.yml`)

A GitHub Actions workflow is configured to automate the following steps on every push to the repository, ensuring code quality and automated data processing.

**Workflow Steps:**
1.  **Checkout repository:** Fetches the code.
2.  **Set up Python 3.11:** Configures the environment with Python 3.11.
3.  **Install dependencies:** Installs `pandas`, `ruff`, and `openpyxl` (for `.xlsx` reading).
4.  **Convert `data.xlsx` to `data.csv`:** Uses a Python one-liner with Pandas to perform the conversion.
5.  **Run Ruff Linter:** Checks `execute.py` (and other Python files) for linting errors and style issues.
6.  **Execute data processing script:** Runs `python execute.py` and redirects its output to `result.json`.
7.  **Publish Results via GitHub Pages:** The generated `result.json` is uploaded as an artifact and deployed to GitHub Pages, making it publicly accessible.

**`ci.yml` Code:**

```yaml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: write # Needed for actions/checkout@v4 to convert data.xlsx to data.csv and commit
  pages: write
  id-token: write

jobs:
  build-and-publish:
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas ruff openpyxl # openpyxl is needed for pandas to read .xlsx

      - name: Convert data.xlsx to data.csv
        run: |
          python -c "import pandas as pd; df = pd.read_excel('data.xlsx'); df.to_csv('data.csv', index=False)"

      - name: Run Ruff Linter
        run: ruff check .

      - name: Execute data processing script
        run: python execute.py > result.json

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'result.json' # This uploads result.json to be served by GitHub Pages

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
```

## `index.html` - Responsive Web App

The `index.html` file provides a single-file responsive HTML application using Tailwind CSS. It serves as a basic landing page for the project and demonstrates a clean, modern design suitable for web-based project documentation or dashboards.

## License

This project is open-sourced under the MIT License. See the `LICENSE` file for details.